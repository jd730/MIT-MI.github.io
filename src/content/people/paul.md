---
name: "Paul Liang"
title: "Faculty"
avatar: "https://dam-prod.media.mit.edu/thumb/2024/10/02/paul-liang-headshot.jpg.800x800.jpg"
scholar: "https://scholar.google.com/citations?hl=en&user=pKf5LtQAAAAJ"
website: "https://pliang279.github.io/"
github: "https://github.com/pliang279"
twitter: "https://twitter.com/pliang279"
---

Paul Liang is an Assistant Professor at the MIT Media Lab and the Department of Electrical Engineering and Computer Science. He is the founding director of the Multisensory Intelligence research group, which studies the foundations of multisensory artificial intelligence to create human-AI symbiosis across scales and sensory mediums, enhancing productivity, creativity, and wellbeing.

Paul received his PhD in Machine Learning at Carnegie Mellon University, advised by Louis-Philippe Morency and Ruslan Salakhutdinov, and was a visiting researcher at the Simons Institute at UC Berkeley in summer 2024. During his PhD, he also spent time at the research labs of DeepMind, Facebook, Nvidia, and Google. Previously, he received an MS in Machine Learning and a BS with University Honors in Computer Science and Neural Computation from CMU.

Paul's research builds the theoretical foundations, large-scale resources, and neural network architectures to learn from multisensory data. These approaches are widely used to train and evaluate today's multimodal generative AI models used throughout academia and industry.  In collaboration with practitioners, he has deployed these systems for problems in mental health, cancer prognosis, and robot control. His research has been recognized by the Siebel Scholars Award, Waibel Presidential Fellowship, Facebook PhD Fellowship, Center for ML and Health Fellowship, Rising Stars in Data Science, and four best paper awards at international conferences and workshops. Outside of research, Paul received the Alan J. Perlis Graduate Student Teaching Award for designing a new pedagogy for multimodal AI.